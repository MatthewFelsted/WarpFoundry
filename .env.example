# Copy this file to .env and fill in your API keys.
# NEVER commit .env to version control.

OPENAI_API_KEY=sk-proj-your-key-here
ANTHROPIC_API_KEY=sk-ant-your-key-here
GOOGLE_API_KEY=your-google-api-key-here
XAI_API_KEY=xai-your-key-here

# Optional: set the display name shown in the GUI branding/header.
# WARPFOUNDRY_PROJECT_NAME=WarpFoundry
# CODEX_MANAGER_PROJECT_NAME=WarpFoundry   # legacy alias

# Local Ollama Setup
# Ollama lets you run models locally for free, offline, and private.
#
# Quick start:
#   1. Install Ollama:  https://ollama.com/download
#   2. Pull a model:    ollama pull gemma3:27b
#   3. Start server:    ollama serve
#   4. In the GUI, check "Local Only" or use --local-only on the CLI
#
# The manager auto-detects installed Ollama models. The GUI brain model
# dropdown dynamically shows whatever you have pulled.
#
OLLAMA_BASE_URL=http://localhost:11434
# OLLAMA_AUTO_START=false    # Set to true to auto-start Ollama if not running

# CUA (Computer-Using Agent) Setup
# CUA lets an AI visually test your app by controlling a browser.
# It takes screenshots, clicks buttons, fills forms, and reports issues.
#
# Requires:
#   pip install warpfoundry[cua]
#   python -m playwright install            (installs Chromium + headless shell)
#
# CUA uses OPENAI_API_KEY (OpenAI CUA) or ANTHROPIC_API_KEY (Claude).
# No additional keys needed beyond those already set above.
#
# Usage:
#   CLI:      warpfoundry visual-test --url http://localhost:5088
#   GUI:      Enable "Computer-Use Agent" in Pipeline config
#   Pipeline: Enable CUA in pipeline config so visual_test phase runs automatically
#
# CUA_DEFAULT_PROVIDER=openai     # "openai" or "anthropic"
# CUA_HEADLESS=true               # Set to false to see the browser in action
# CUA_OPENAI_MODEL=computer-use-preview   # Requires API Tier 3+ or allowlist

# Brain model preferences
# Used by WarpFoundry's thinking layer (brain, optimizer, scientist).
# When "Local Only" is enabled (GUI toggle or --local-only), these
# are overridden to use your first installed Ollama model.
#
# AI_LEAD_MODEL=gpt-5.2
# AI_CHEAP_MODEL=grok-4-1-fast-reasoning
# AI_MEDIUM_MODEL=gpt-5.2
# AI_FREE_MODEL=ollama:gemma3:27b
